{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from pykrx import stock\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import font_manager, rc\n",
    "import platform\n",
    "if platform.system() == 'Windows':\n",
    "# 윈도우인 경우\n",
    "    font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "    rc('font', family=font_name)\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "stock_list = pd.DataFrame({'종목코드':stock.get_market_ticker_list(market=\"ALL\")})\n",
    "stock_list['종목명'] = stock_list['종목코드'].map(lambda x: stock.get_market_ticker_name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list = pd.DataFrame({'종목코드':stock.get_market_ticker_list(market=\"ALL\")})\n",
    "stock_list['종목명'] = stock_list['종목코드'].map(lambda x: stock.get_market_ticker_name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종목코드</th>\n",
       "      <th>종목명</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>060310</td>\n",
       "      <td>3S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>095570</td>\n",
       "      <td>AJ네트웍스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006840</td>\n",
       "      <td>AK홀딩스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>054620</td>\n",
       "      <td>APS홀딩스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>265520</td>\n",
       "      <td>AP시스템</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     종목코드     종목명\n",
       "0  060310      3S\n",
       "1  095570  AJ네트웍스\n",
       "2  006840   AK홀딩스\n",
       "3  054620  APS홀딩스\n",
       "4  265520   AP시스템"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAFkCAYAAAD165gcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABQHklEQVR4nO3deXzcVb3/8deZPfueptmadKd7aSm10FKgAipcQb0qCiiouHvd16v33p+goHIvXq8b4BUvCq5YEFkUpLRsXem+N2mbfV8mmX3m/P6YmTRpJmsnme3zfDz6IJn5zjefhjTvObvSWiOEEEKI+GCIdQFCCCGEOEeCWQghhIgjEsxCCCFEHJFgFkIIIeKIBLMQQggRRySYhRBCiDhiinUBAIWFhbqqqirWZQghhBDTYvfu3e1a66JIz8VFMFdVVbFr165YlyGEEEJMC6XUmZGek65sIYQQIo5IMAshhBBxRIJZCCGEiCNxMcYshBAi+Xi9Xurr63G5XLEuJWZsNhvl5eWYzeZxv0aCWQghxJSor68nKyuLqqoqlFKxLmfaaa3p6Oigvr6e6urqcb9OurKFEEJMCZfLRUFBQUqGMoBSioKCggn3GEgwCyGEmDLxHMpPPPFEVK4ZzWT+/tKVLYQQIql99rOfZe/evQA4HA6WLVvGQw89xI9+9CPe/va3j/uasGPHjvHVr36V/v5+ADIyMrjnnntYsGBBVOqVYBZCCJHU7r///oGPn3zySY4ePTqpawACgQC33XYbjzzyCPPnzwfg+PHj3Hrrrbz22msYDBfeES3BLIQQImk5HA5+8IMf0NXVRU9PD3v27OHRRx+d8DVhdXV1LFiwYCCUAebPn8+CBQuoq6tj1qxZF1yzBLMQQogp9x9/OcThxt6o3nNRaTb/dsPiUa9JT09n06ZNlJSU0NnZyfe+9z0WLVoEBFu/N954I+vWrRvXNV/+8pcpLS3l5MmT9PX1kZmZCUBfXx8nT56ktLQ0Kn8vCWYhxJTod/vodnopy02LdSkixa1bt47GxkY+//nP87vf/W7gcYPBwObNmwc+H881ZrOZe++9l3e9611UVFQAcPbsWe69994JrVUejQSzEGJK/PjFkzyxt5FXvnpVrEsRcWCslu1UevbZZ7nrrrt46KGHmDlz5qSvCVu/fj3PPvssv/zlL/H5fDz44INRrVeCWQgxJZp7XbTaU3fHJxEfvF4vO3bs4MknnyQ/P3/S10RiNpunZDmYBLMQYkr0uXx4/RqPL4DFJFsmiNgwm81861vfuuBrAF544QW++93vDnv817/+9cDHX/7yl7nmmmsmXuggEsxCiCnR5/YB4PT4JZhFUrj66qu5+uqrp/zryL8WIcSUCAdzv8cX40qEiOz555+PyjXRJsEshJgSfa5gIDs8/hhXIkRikWAWQkyJcIvZIS3mlKa1jnUJMTWZv78EsxBiSpwLZmkxpyqbzUZHR0fKhnP42EebzTah18nkLyFE1PkDeiCQpcWcusrLy6mvr6etrS3WpcSMzWajvLx8Qq+RYBZCRF24tQzSYk5lZrOZ6urqWJeRcKQrWwgRdf2Dg9ktwSzEREgwCyGibmiLWbqyhZgICWYhRNTZXefCuF+6soWYkDGDWSlVpJS6Wyn17dDn71VKbVFK7VJKfS3C9TcqpbYppbYrpd4zFUULIeLb4BazU4JZiAkZT4v5PsANhM+zOqm13gisAd6ulCoKX6iUygC+CGwCrgK+qpSa2DxxIUTCGzzGPNbOXy7v+ILbH9DjvlaIRDZmMGutbwO2Dvp8V+i/AaAD8Ay6fC3wgtbarbXuB7YDC6NasRAi7vW5xtdiPtnax5J/e4799d1j3vN//nGSq+97iUAgNdfEitQx6TFmpdQngG1a655BDxcDgxesdQB5I7z+zlB3+K5UXuMmRDKyh1rM+RmWUceYjzXb8QU022s6x7zn0weaaOh2cqqtL2p1ChGPJhzMSqkspdTPgFat9T3nPd3D0CDOY2hQD9BaP6C1Xq21Xl1UVBTpEiFEggq3mIuzrDhH6cpu6nECcKSpd9T7Nfe4ONZiB2D3ma6Bx2va+vj87/dS3+Vg24k27v7r4QstXYiYm8wGI/8D3K21Ph7huR3AN5RS9xAck14CHL2A+oQQCajP7SXNbCTTaqJ/lHXMzT0uAA6PEcxbjwff35sMij1nu3jvmkr21nVzx8M76ez30OPwcripl6YeF3dumENRljV6fxkhptlkgvl6YJZSKvz5/wP6gDla68eUUg8DLwNO4N+01rKIUYgU0+f2k2kzkW410eP0jnhdUyiYT7b24fb5sZqMEa976UQbxVlWFpVms+dsNy8ea+UTv95DYZaFaxdX8tiOswPXvnG2i2sWl0T3LyTENBpXMGuttwBbQh8XjHDZjtDzDwIPRqE2IUSC6nP7yLKaSDcbaep2jnhdU48TpcAX0Jxo6WNJWU7E67bXdLJhXiHVhRlsOdbGR361iwUlWfzy9kvItJp45WQ7C0uyePFYK2/UdUswi4QmG4wIIaKuz+UNtZiNo+6V3dzjYkVFLjDyOHO3w0N7n5uFM7NYU50PwKWz8/ntnWspzrKRbjHx3Gc38LNbVrFoZjZvnO2KeB8hEoUEsxAi6vrcPjKtJtItxhG35PQHNC12N2tnF5BmNvLcoWZ8/sCw60619QMwpyiTS2cX8KePv4lffnANWTbzwDVpFiMGg2JlZR7763si3keIRCHBLISIuj63nwyriQyLacQWc5vdjT+gKctN41NXzeX5I618+rE3hp3dG14eNacoE4BVs/KxmCL/6lpZmYvD4x+YwS1EIpJgFkJEXZ/bS5bVRJrFiNsXwB9hU5DwUqnSXBufvHIuX7luIc8cbOZ3O+uGXHeqrQ+L0UB5XtqYX3dlRXC15htnuy/8LyFEjEgwCyGiSmtNZ5+HnHQzGZbg/NJI3dnhpVIl2cHA/eiG2aydnc/dfz0yENoAp1r7qSpMx2Qc+9dVRX4ahZkWCWaR0CSYhRBR1dnvod/jpzI/nXRrcPlTpO7sxlAwz8wJbqdvMCjufecyvIEA//rngwNd2jVtfQPd2GNRSrGiIo836mQCmEhcEsxCiKg60+kACAazZZRg7nZiMxvITT83iWtWQQZfvGYBLxxt5cl9jXh8Ac50OphbPL5ghuA4c01bP90Oz9gXCxGHJJiFEFF1tiMYzLMK0kkPdWUPPm0q7ERrsCU8aLMiAG6/rJqVlbn8+5OHeO5QM/6AHneLGYLBDPBGXffk/gJCxJgEsxAiqs6Egrk871yL2RnhuMajTb0sLMke9rjRoPj+u5bR7/bz6cfeoCw3jfXzCsf99ZeX52JQ8MYZ6c4WiUmCWQgRVWc7HZRk27CZjQN7Vjd0Dd39q6PPTavdzUUzsyLeY25xFt+8YRGXVufzp4+voyBz/HtfZ1hNrJ6Vzx9316f0+c1Oj5+dpzuHLT8T8U+CWQgRVWc7+6nMTwdgblEmaWYje8/rVj7WHFxnHKnFHHbr2ln87qNvoiQ0OWwiPvvmeTT2uHjktTMTfm2yuP/54/zzz17jll9sp0aOykwoEsxCiKg60+GgsiAYzCajgaXlOcPGe4+Eg3mEFvOFWjenkA3zi/jxlpP0ukY+RCNZ+QOazXsbmF2Uwf76Hq67fxv3P388pXsQEokEsxAiapweP61290CLGWBlRS5HGntx+86FwtGmXgozrRROoIt6or587QK6HV5+/tKpKfsa8Wp7TQctvW4+/+b5vPCFK7huSQn3P3+CG3/8ypD/DyI+TebYRyGEAIKzrb//3LGBWdf9oY1EZhWcC+YVFbl4/AGONNlZWpbDnrNdbK/tHHF8OVqWlOXwT8tL+cXLtXzgTVUUZ0+8SzyR1Lb388zBJj62YQ6Pv9FAptXEpotmYDMb+e+bV7JhfhFf/MM+thxr41o5fSuuSTALISZt95kuHn71NIWZVizG4LKnOUUZXFyZN3DNitDypX974iD1XU46+j2YjYqPXjF7yuv7wjXzefpAEz984QR337R0yr9eLP1+Vx0/3XIKo1I8ubeRd64qx2Y+d771jStKueeZIzyxt0GCOc5JMAshJq0rtInH7z66dsS1xjNz0phTlEFNWz8bFxZzzaIZbFxQNOR0qKkyqyCD911ayW+2n+XD62dTXZgx5V8zVsITvL77zFEsJgOfvmrukOdNRgPXLyvl0R1n6XV5yZ6G77+YHBljFkJMWld/MJjz0i2jXvfXz6xn9zffzI9uXskNy0unJZTDPn3VPKwmAz/bktxjzTVt/RRmBv8/fOBNsyjNHX7oxw3LZ+LxBdh6vG26yxMTIC1mIcSkdTm8KAU5aaMH7eAu1elWlGXlygXFvHS8Da31sJ3GkoE/oDnT4eD2y6p486IZLCvPjXhdRWhSXpcj9WaqJxJpMQshJq3b4SHbZsZoiO+wWze3gOZeFzXt/bEuZUo0dDnx+APMLspgddXI51WH3yC5ZdlUXJNgFkJMWqfDS156/I9VXj43uKXnqyfbY1zJ1KhpD44vVxeOvqe4NRTYbl9gymsSkyfBLISYtG6Hh9wxxpfjQWV+OmW5abxysiPWpUyJmrZgT8DsotEnt1mMBpSSFnO8k2AWQkxal8OTEC1mpRSXzS3g9dokDeb2PrJtJgoyRn+TpJTCajJIiznOSTALISatq9875ozseDGrIINuhzfptqX0BzQH6nuojnCEZiRWkzHpvgfJRoJZCDFpidKVDZAbatl3J+iM5Da7m2cONA15zOsP8Lnf7WVffQ83rSgd132kxRz/JJiFEJPi8QXo9/gToisbzq217nZ6YlzJ5PzspVN8/Dd7ONkanOjl8QX41KN7eHJfI199y0I+eFn1uO5jMxslmOOcBLMQYlK6Q7t+5Y4xrhkvwi3mrv7EbDG/EppR/tT+RlxePx/79W6eO9TCv92wiI9dMWfc97GaDNKVHedkgxEhxKSEN6lIlBZzblqoxexIvBZzR5+bo6GjMp/Y28iu0128cqqd79y0lPddWjmhe1nN0pUd76TFLISYlPA+2Yky+SsvIzTG7Ay+oTjS1MsDW0+htZ7U/Y632Pnxiyfx+qc+5F6v6QTgXavKqW3v59VT7fzgXcsnHMoQnPwlRz/GN2kxCyEmZaArO0FazOE3EOE3FD976RRP7G1EofjIhomfdPXH3fU8sLWGA/U9/Oh9KzEbp66d88qpdjKtJr72loU09Th535pZvG3ZzEndy2Y24PJKizmeSYtZCDEpnf3hruzEaDHbzEasJgPdDi9aa1471YHRoLjn2aPsPN054fu12d0oBc8eauZvh1qmoOKg1051sPmNBtbNKaAg08pvPrx20qEM0mJOBBLMQohJSbSubAjW2tXv4VRbP612N1+9biGV+el88jd7aLO7B64LBDT//uQh3vrDbSN2Vbf3uVlYkg0wMFM62lp6Xdzx8E7KctO466YlUbmn1WTALS3muDZmMCulipRSdyulvj3osU1Kqb1KKVuE69+jlNqmlNqplLo12gULIeJDt8OD1WQgzRK7k6MmKjfdTLfTy2s1wR3Arlk8g5+8/2J6nF4+89gbNHQ7+exv3+Cmn77Kw6+e5nBTLy+PsL92m91NeV4apTk2atuHBvODW2uGrTmejKf2N+H0+vnZrasozhr263ZSZLlU/BtPi/k+wA2YAZRSNwJXAsOmNiql8oBPAlcDVwCfU0plR6tYIUT86OjzUJhpjXUZE5Kbbqbb4eG1U+2U5tiozE/nopnZ3HXjEl6r6WDTfS/xt8MtaK350rULyLKZeGpf5IBt73NTmGmlqjCD2g7HwOPbazq4++kjfPeZowMTy44126nvckS8z2j+ur+RxaXZzCka/XCKiZDlUvFvzGDWWt8GbB30+Wat9TeASD9lc4E3tNYerbUD2A5cFK1ihRDxo8Xuojg7sYI5L91Cl8PLztNdrJ1dMLCF5T+vruCWtZVYTAZ+/eFLefJTl/PJK+dy7eIS/na4ediYrM8foKPfQ1FWMJhPh46T9PoDfPOJgxgNirOdDg409ADwid/s5nO/2zuhWhu6new5281bl05+PDkS2fkr/kV7jPkU8CalVLZSKgNYwwgzv5VSdyqldimldrW1tUW5DCHEVGvtdTMjSt2r0yU33cLZDgdtdjfLynOGPPftty9hxzeu5uLKvIHHrl82E7vLx9f+dIAe57mNSTodHrSGoiwr1QUZ9Di9dPV7ePiV0xxv6eOedyzFbFT8dX8TXn+A0x0Odp7uoqnHOe5aw13hb4tyMAe7sqXFHM+iGsxa607gLuAp4CGgFjg9wrUPaK1Xa61XFxUVRbMMIcQ0aOlNvBZzbroZT2gy19Ly3CHPBU9eGjpefsX8Ij515Vye2NfINf/1Ei8cCc6+Dk8UK8q0UFUYPGrx9ZoO7n/+OFctLOZdq8pZP6+Ip/Y3Ud/lxB8Idmk/faB5xNp21Hby9T8fGOj+fmp/E0vKsgfuHy3BruzApNdvi6kX9VnZWusntdYbgK8AAa11Q7S/hhAitlxeP70uHzOyE6vFHN6lzKBg0cyxp78opfjitQv48yfWkZtm4UO/2sXnf7eX+q5gy7coy0p1YToA39h8EF9A8+83LEYpxZULi2nodvLqqeDkMZvZwF/3N0b8OoGA5pubD/Lo9rPUdTqp63Swt66bty0d38EUE2E1B998eKZhYxQxOVHZYEQptQaYo7V+TCn1KFAJ2AlOBBNCJJnW3mCLsTgr0VrMwaVd82dkTWg2+bLyXJ789GX89wsn+PGLp6gLTeQqzLRSkmPDoKCz38PnNs2nsiAY1EvLgl3lT+4NhvGta2fx4LZaDjb0sKRsaDf6s4eaOdYS3HJzf0M3jd3B4I92NzYEW8wAbl9gWA+BiA/jajFrrbdorb963mMbtdau0Mc7tNaPhT5+n9b6cq31W7TWNdEvWQgRay12FwDFCdZizk0LtpjPD8bxsJqMfPGaBRRmWtl5ugsIBrPVZKQyP51ZBel89IpzO4gtLMnCZFDsON1JptXEp6+eR7bNxI/+cWLYvX/xci2zCzMwGxUHGnr46/4mlpXnDIR8NIVbzDIzO37JBiNCiAkLt5hnJNgYc17oJKzzJ36Nl1KKtbPzAUi3GMmwBjsdf/z+i3nkjkuxmc+1QG1mI/NnZKE1VBWmk20zc8fl1Tx3qIUjTb0D12mtOdZsZ8P8IhaWZPP3Qy3sq++ZktYyDGoxyyYjcUuCWQgxbv6A5tmDTQOzixNtVvaS0hzevbqc65aUTPoea2cXAMHx5bDFpZFbt+Hu7KqC4ASu29dVk2U18d8vnGs1d/R76HP7mFWQzpKyHGpCS6+ivUwqLPzmQZZMxS8JZiHEuP39cAsf+/UefvXaaSxGQ8IcYBGWZjHyvXctv6BdtMLBPJ7NVZaUDw3mnHQzt19WxTMHmznaHGw1h9dAVxVkDAT58opcKvKj340N51rM0pUdvySYhRDj9npoK8u6TidFWdaBDTpSyZyiDIqzgpO+xrIitCRrTvG5JU93XF5NptXEj144CcDp0K5hVYUZLK8IBvP1U9RahqGTv0R8kmMfhRDjFg5mSLzx5WhRSvHL2y8h2zZ2b8HS8hx++cFLuGxu4cBjuekWPriuih9vOcnxFjtnOvoxGhRluWlYTAZ+8YHVXD6vcJS7XphzXdnSYo5X0mIWQoxLt8PDsRY7l4dCJlqHKiSixaU54+5qvnJhMRbT0F+1H7q8mnSzkf9+4QSnOxwDoQxw9UUzpnQZk0z+in/SYhZCjMuO2k60hk9dNZf6LgcLZ2bFuqSElZdh4QPrqvjpS6cozLSysGT6vpfh0JcWc/ySFrMQYlx21HZiNRlYWZnL3z53Bf9y9bxYl5TQPrx+NmlmI21298DksOlgNcsYc7yTYBZCjMu++m6WlOVgNRmxmAwpOfErmvIzLNz2pioAZk3BRiIjsckGI3FPglkIMSafP8DBht5Jb8whIrtzw2w2zC/iivnTd5CPzMqOfzLGLIQY06m2fpxevwRzlOVnWPi/O9ZM69eUyV/xT1rMQogx7avvBoKHOYjEJl3Z8U+CWQgxpgP1PWRZTVRP4yQlMTVMBoVBSVd2PJNgFkKMaX9o4pfBIBO+Ep1SCqvJKMul4pgEsxBiVB5fgCNNdhlfTiI2s0FazHFMglkIMapjzXY8/oCMLycRq8koY8xxTIJZCDGq/Q3dwOTPMBbxxyot5rgmwSyEGNX+uh7y0s2U56XFuhQRJTaTUZZLxTEJZiHEqPbVd7O0PFd2+koiVrMBl0z+ilsSzEKIETk9fk609rFcurGTSprZiMMjwRyvJJiFECM63NSDP6BZWibBnEwyrCacEsxxS4JZCDGi/fU9ACyvyI1tISKq0ixG+j2+WJchRiDBLIQY0f76HoqzrMzItsW6FBFFGRYjDre0mOOVBLMQYkT767tl/XISSreYpMUcxySYhRAR2V1eatr7Zf1yEsqwGnF6/GitY12KiECCWQgR0cGGXrSWjUWSUbrFhC+g8fhlLXM8kmAWQkS0X456TFrpluDRjzLOHJ8kmIUQEe2t66YiP438DEusSxFRlmExAcg4c5ySYBZCDKO1ZteZLlbPyo91KWIKpFuDLWZZyxyfJJiFEMOc7XTQZnezalZerEsRUyDcld0vwRyXJJiFEMPsOt0FwOoqCeZklB7qyna4pSs7Ho0ZzEqpIqXU3Uqpbw96bJNSaq9SatiuA0qpK5VSW5VS25VSt0a7YCHE1Nt1possm4n5xVmxLkVMgXNjzNJijkfjaTHfB7gBM4BS6kbgSsAzwvX/AdwAXA58UcmRNEIknN1nOrm4Mg+DQf75JqPwGLNDJn/FpTGDWWt9G7B10OebtdbfABwjvMQB5ACZQJ+WFexCJJRAQFPb3s9FM7NjXYqYIuEWs5wwFZ+mYoz5P4FdwEHgf0e6SCl1p1Jql1JqV1tb2xSUIYSYjC6HB69fMyPbGutSxBRJC0/+kjHmuBTVYFZKFQP/AswK/blKKbUs0rVa6we01qu11quLioqiWYYQ4gK02t0AcnBFEhvYYERazHEp2i3mQsCntXZqrX1AF1Ae5a8hhJhCLb0uAGkxJzGz0YDFZJBgjlOmaNxEKbUGmKO1fkwptVMp9Sqggb3As9H4GkKI6dHaG2wxF2dJizmZZViMMvkrTo0rmLXWW4At5z22cdDHO4AdoY/vAu6KVoFCiOnVag+2mIuypMWczNItJvplr+y4JBuMCCGGaOl1k5tuxmY2xroUMYXSpcUctySYhRBDtPS6mCHd2Ekv3WqSMeY4JcEshBii1e6mWCZ+JT0ZY45fEsxCiCFae10y8SsFpFuM9Lv9/O1QswT0GP52qJkn9jZM29eTYBZCDAgENK12tyyVSgHpFhPHW+zc+chufvP62ViXE9ce3XGWh7bVTtvXk2AWQgzocnjwBbRsLpICMqxGfIHgjsnbaztjXE186+r3kJ9hmbavJ8EshBjQ0hve9UtazMkufPQjwM7TnQQCcqzBSDokmIUQseAPaH74wnGUgrnFmbEuR0yxjNC2nHOLM+lxejnR2hfjiuJXV7+HvHQJZiHENHtwWw3PHWrhm29bxFw5hznpZViDLeYvXbsAgB2nU6s7+/WaDq67fyt2l3fU61xeP/0ePwWZEsxCiGn28ol2Fpdmc8fl1bEuRUyDt68o47vvWMo1i2ZQnGVlZxKNMx9vsfPwK7U8tb9xxC76+58/ztFmO0ea7BGfd3n9/ONoC10OD4C0mIUQ0+9os13OYE4hJTk2bl5TiVKKS6rz2VHbidaJP858uLGXd/zkVf79L4f51KNvcN/fjw275lBjD6/XBN+InG7vj3ifzW80cMfDu9h1ugtAxpiFENOro89Ne5+bhSXShZ2KLq3Op7nXRX2XM9alXBCfP8BH/m8XmVYTz3/+Cm5eU8mPXzzFo9uHLgf71aunSbcYMRsVtR2Rg/lwUy8Ae+u6AQlmIUSU7Trdye92nh34JXO+Y83B7rwFEswp6ZKqfAB2JHh3dke/h4ZuJ5+8cg5zizP59tsXc+WCIr75xEFePNoKBCc5/v1wC9ctLqEiP53atsjBfDT0b2J/fTcA+Rnmafk7gASzEElPa83tv9zJV/50gHf+9FVeOt427JqjEswpbcGMLLJtJnYm+ASwbkdwIld+RnC5n8lo4H/edzELS7L45KN7ONjQw966brocXq5cWMzswgxOR2gxa60H3qwebOgdcs/pIMEsRJLrdfqwu318YuMcFszI4hO/3k1Tz9Auy2PNdvIzLBRlyvrlVGQwKFZX5Sf8zOzu0ESt3PRzrdsMq4n//eAl5KVbuP3hnfxm+xmMBsWGeUVUFQSD+fwJYq12Nz3OYMg7vX6Ugpw0aTELIaKkqTcYwotKs/neu5bR7/GzMzShJexoi50FM7JQSsWiRBEHLqnKp6atn/Y+d6xLmbSuUIt5cDADzMi28cvbL8Hl9fP4ngZWVeaRk26mqjADlzdAc69ryPXhHqTwWu/cNDNGw/T925BgFiLJNfUEf+nMzLExf0YWJoPiePO5JSInW/s43NjDkjKZkZ3K1lQHx5kTedlUjzPcYh4+UWv+jCx+fusqLCYD1y+fCUB1YQYwfGb2seZg9/X6eUXA9E78AjCNfYkQIpG1hIJ5RrYNi8lAdWEGx1qCwRwIaL72+H7SLSbu3DAnlmWKGFtaloPNbGDH6U7esnRmrMuZlPAYc+4I3c7r5hSy+183kRnaXCUczF/784Eh65Tru5wUZ1lZWp7Ds4eaJZiFEJPj9PhxeHwUnDdO3NTjQikGjnKcX5LFwYYeAH6z/Qw7T3fx/XctoyhLxpdTmcVkYEVFbkJPAOt2erEYDaSHuqAjybKdC+2ZOTbef2kldectE1uUZuaqBUXkhQJZglkIMSnff+4YW4638o8vbBzyeEuvi8JMKxZTcORqwYwsnj7QxMlWO/c8c5T18wp516ryGFQs4s2aqnz+58WT2F3eIQGWKLodHnLSzeOeK6GU4u6blo74/O4zwTcp0x3MMsYsRJI429lPTVs/To9/yONNPS5KBh3jOH9GFlrDR/5vNwEN37lpqUz6EgBcUp1PQDOwK1ai6XZ4R+zGnoyy3HRgerfjBAlmIZJGZ39w4suZzqETWZp7XJTknAvm8Frl2vZ+vnjtAiry06evSBHXVs/KpzTHxr9uPjBsSV0i6HZ4h83IvhDFWVbecXEZVy0sjto9x0OCWYgkEZ74crrdMeTx5t6hLebK/HQyLEZWVOTywXVV01miiHNpFiO/+OAl9Lv9fHPzwViXM2FdDk/EGdmTZTAo/vPdK1gd2hltusgYsxBJojO0ucKZQTsZOTw+epzeIS1mo0Hxm4+spTwvbVrXZorEcNHMbN69uoJfbz+D0+MnbZSJVPGmx+ll6TRuBDJVpMUsRBLwB/TATkWnO861mJtDS6UGt5gBVlTkUii7fIkRXLGgCI8vwOu1HbEuZUKi3ZUdKxLMQiSBHqeX8Il94c0StNY8faAJCC4LEWK8Lq3Ox2Y28NKx4fuqxyuX14/T649qV3asSFe2EEkgfJi71WTgTEc/Lq+frz9+gMffaODqhcVcUj29Y2QisdnMRtbOLoh44Em8CvcYSYtZCBEXukIzspeU5dDY4+IdP3mVP+9t4HOb5vPgbasxG+WfupiYqxcWU9veP7AZTbw7t+tX4reY5V+rEEkgvFRqZUUuAHVdDn7xgdX8y6Z5GGSCl5iEf1pRRprZyCOvnYl1KRG9crKdmx94nV+9epoepzfiyVKJSrqyhRinfrcPrz8Ql2NY4dbCO1eVE9Bw65tmDewDLMRk5KSZuXFlGY/vqedrb10YVz/3J1vtfOyR3fi15rWaDr7z9BEumhk8hCUZgllazEKM03/85RDve3B7rMuIKLxUqjI/nW/dsEhCWUTFrWtn4fYFePpAc6xLGeKeZ45iNhn4++ev4KlPX867VpVzsrUPo0EN7AmfyMYMZqVUkVLqbqXUtwc9tkkptVcpZTvv2suVUlsG/elUSi2bisKFmG7HWvo43NQ7MMkknnQ5PFhMo2/eL8REXTQzi/wMC2+c7Rr74mlU3+Vk1aw8ynLTWFKWw903LWX716/muc9uSIrDWMbTYr4PcANmAKXUjcCVgOf8C7XWL2utN2qtNwK3AM9rrfdHrVohYqixO7hFYTxOhunq95CfbpE9r0VUKaVYVp7D/vr4+plv73MPW4efYTUxtzgzRhVF15jBrLW+Ddg66PPNWutvAI6RXwXAt4C7R3pSKXWnUmqXUmpXW1viTMkXiet7zx7lo4/smtRr3T4/bXY3APvqu6NYVXR0JcnGCiL+LCvP5USrHYfHF+tSAPD5A3T0eyjKjJ8x72ibkjFmpdQMYKbWet9I12itH9Bar9Zary4qKpqKMoQY4mBjL38/3DIwe3MiwjtoAeyvi6/WA4RazNN8NJ1IDcvLcwhoONjQO6HXnW7vZ9uJ6De6Oh0etCYpuqxHMlWTvz4I/HKK7i3EpDjcPgIaXjk58W0GG0IHqRdnWeOyxdzp8Awc6i5ENC0rzwVg/zh+7r3+AE8faOKWh7az8QdbuPUXO6J+SlW7PfjGOpm3lJ2qYH478PQU3VuISekPnVO89bzdjBweH5957A1ePdk+4msbQuPL1y0poanHRavdNeK1sdDV7yFPurLFFCjKslKaY2PPGBPA9tZ1s+6ef/CJ3+yhtr2fd1xcBsDxlr5xfy1/QPP53+8ddR5HW19wSKlQWsyjU0qtUUrdHPo4H/BorePrN5dIeeExsq0n2jjRYh/484Xf7+PJfY38evvIGyk0dgd/nMPnsh5rtk99weNU1+mgy+FlTlFyTHwR8efNi2bw3KEWatpGDtmXT7TRZnfz0G2r2frlK/nXty0C4ETL+P+ttNndPL6ngT+/0TDiNe2huR5FSdxiHtcGI1rrLcCW8x7bOOjjHcCO0MedwEaEiDP9bj8ZFiNNPS7e/F9bhzw3I9vKyyfa8Qd0xKMQG7udFGVZWVyaA8CJlj7Wz4uPuRHbTgRb+uvnFca4EpGsPnnVXP6wu577/nacH7//4ojXtPd5yLKa2LRoBgD5GRYKMiycbB1/i7nXFVyKeGCUWeDtKdBilp2/RMpweHy8e3UF6+YU4PEHBh7Pz7DQZnfzL7/dy/76blZW5g17bWOPk9LcNAozLeSmmzk5Ssthur18so2ZOTZpMYspU5xl48OXV/Pf/zjJnXXdLA9t/TpYW597WFjOLc7kxASC2R4K5oONPSO+SW6zu7GZDWQk8Zp92flLpIRAQOPw+MlJM3PN4hKuX1Y68GfdnELWzytCKXj5RORx5oYuJ+W5aSilmFecyckJjJtNJX9A88rJDi6fWyhrmMWU+siG2eRnWLjnmaPo8Bmjg7Tb3RSet4Rp3oxMTrTYI14fSa8zONzk8Pg5NcKb3/Y+N0VZ1qT+eZdgFinB4Q1O/MqwRn6XnZ9hYUlpDs8cbMY7qDXd7fDw0LYa6roclOYGN7oLtgLiY4z5QEMPPU4vl0s3tphiWTYzn75qLq/VdLA1whvYSJt+zCvOotflo83uZkdtJ+/++Ws4Q5MwIwl3ZQMjbmrS3udJ6hnZIMEsUoTDHXwnnm4ZefTmw+urOdzUy7eeOMiLx1r5wu/3cel3XuCuvx5haVkOt6ydBcDc4iy6HF46QmNdsfRyaJ3oZXMlmMXUe9+llVTkp3HPM0cJBIa2giMFZngnrhOtffxhVx07ajt5vWbk5Yq9oe1uDWrk5Vlt9uFvAJKNjDGLlBBeKjVSixng7SvK2F/fwy9eruWxHXWkW4y8c1U5t1w6i0Wl2QPXzRv0y6Ygxr8gtp1oZ3FpdtL/ohLxwWoy8sVrFvAvv93Lk/sauXFlcEmUxxegx+kd9nM4f0YWALvPdPFyaDnithPtXBla3XC+XlfwDfSKilxeO9WB1npYl3V7n5tVVcPngSQTCWaREvrH0WIG+Ne3XcQNy0txef0sLs0myzZ8bfC8GeeCee3sgugXO4K9dd28dqqDG1eWMjMnjX63jz1nu7jj8uppq0GIG5aV8vOXavjB347xlqUlWE3GgfPAC7OGjjEXZVl50+wCHtpWQ6/Lh9GgeGWU/QJ6XV4sJgP/vLqCrz1+gDfqurl40GRMnz9Ap0O6soVICo5wi3mMYFZKsaIil7WzCyKGMkBJtg2b2cCZ9v6o1zman790inufPcrl977Ixx7ZzYPbavD6NevnxseyLZEaDAbFV9+ykPouJ49uPwsMWsIUITDfd2nlQEv4PZdUcKzFTmtv5G0uep0+sm1mblheSobFyGOh+4e19wW34yxO4qVSIMEsUkR/aHOR9FG6ssdLKUVpThpNPdO7h05jj4tl5Tl8eH0122s7uP/5E1hNBlYnebeeiD/r5xWybk4BP/rHSewu77nduCIE87WLSyjIsFCZn8771lQC59ben6/X5SU7zUSm1cQ/rSjjL/sbh0wIawxt7xmeiJmsJJhFSnC4x9diHq+ZubaBXxITEQjoSe8a1tTtZGFJFl97y0W89rWr+a/3LOe/3rMCmzl513OK+KSU4ivXLaSz38ODW2tG3Y3LYjJw/3tX8J2blrJoZjaFmRZeOh75cItep5fsUE/VzWsqcHkDPDFoF7Cm0A58M3PSov1XiisSzCIlDLSYo7QpwcyctIFfEhPxveeOce39W9lX1z2h13l8Adr63AO/kGxmIzetLOetS2dOuAYhomF5RS5vWzaTB7fVcqQp+Gbz/DHmsPXzirh8XiEGg2LDvCK2nmjDHxi+ttnu8pFlC755XlqWw+LSbB7dUTewDjp8IEapBLMQiS+8XCrDGp0Wc2mOjVa7C9+gNc8QXPf8w+dPRDxR56/7m/jZS6eA4QdpjKWl14XWyd+FJxLLF69ZgNcf4JHXT5NuMY45uRLgigVFdDu8EZdDBbuygy1mpRQ3r6nkSFPvwJrmxm4X6RYj2WnJPW9ZglmkhPByqai1mHPTCGhosQ9dy/zQtlr+6/njbLrvJX75Su1Aq+BYs50v/XEfF1fmsrAki1dOjTwzNZLweHayd+GJxFJdmMHNayrx+vW4Z0pvmFeEQcGWY8PfnIYnf4W9fUUpaWYjj+0ITgJr6nEyM8eW1Lt+gQSzSBEOT3CphtUUnR/5mTnBlmtT97mWsc8f4A+767ikKo/VVfn8x18Oc+svttPR5+ajj+wiw2rip7esYsP8Ivac6R51B6TzNaXIpBeReD599VzSLcZh23GOJC/DwvKKXLZE6DUKT/4Ky7KZ+aflpTy5rxG7y0tjj4vS3OR/cyrBLFJC+GSpaL3TDv9yaBw0M/vFY2209Lr5yPrZPHz7JXznpqW8eqqDTf/5EvVdTn76/ouZkW0bOERj5+nOcX+9xhSZ9CIST3GWjR/dvJLPvXn+uF+zcX4x++u7h+ye5/L68fgCQ1rMADdfWonD4+fJfY00dTsH3hQnMwlmkRIcHl/UxpdheIv5RIud//jLIWZkW7lqYTFKKd53aSV3bphNl8PLv92wiNVV+QCsqc7HbFQT6s5u6nGSbTNF9e8gRLRcfdGMCR2DunFBEVoPXTZlD611zrYN/RlfXp7DwpIsHnntzJAJkMlMglmkhH6PP2rjyxDsYsuymmjsdrL1eBvv+MmruH0BHrh1NSbjuX9WX71uIS984QpufVPVwGPpFhMrK/N49eTIewafr7E7NbrwRGpYWpZDQYaFLcdaBx4Lr1cOT/4KC7/JPdpsT5kJkBLMIiU43NFtMUNwLfNzh1q4/eGdlOWlsfmTlw07p9ZgUBHPSb5sTiEHG3vodnjG9bXCk16ESAYGg2LD/CK2nmgfOAwjfIDF+V3ZENzH3mYOxpW0mIVIEtFuMUPwF0Rzr4sr5hfxx4+vo2wCLdrL5hagNbx2auxW84kWO2c6HMyUFrNIIhsXFNHZ72F/Q3Ap1EBXdoSlUDlpZq5fVgqkRotZBqxESnB4fMzIiu4/6Ds3zOayuQV86PLZGA0Tm1S2vCKXDIuRV06185YRNglx+/z85MVT/GTLSTKtJt61qjwaZQsRF9bPK0Ip2HKslRUVuee6skfYo/4zV80jP8NCdeHwHqhkIy1mkRIcbj/pUe7KvmxuIXdumDPhUAYwGw2sqc5ne83IM7O//+wxfvjCCd66dCbPf/6KIafsCJHo8jMsLCvPHVjP3BU6oer8MeawyoJ0vv7Wiyb17y3RSDCLlNDv8ZER5a7sCzWnKJP6LufAdoPn23O2izXV+fzwvStjfu6zEFNh4/wi9tV309nv4ViLnSybKelPjhoPCWaREhxu/7i2C5xOJTk2nF4/vU7fsOe01pxq62ducfJ324nUdW7ZVBuHGntZNDM76Xf1Go/4+k0lxAX426FmntjbGPG5Po+PjCgc+RhN4dmlTb1OctKHdt919nvocXqZXZgRi9KEmBbLynPJSzfzwpFWjjT18v5LZ8W6pLggwSySxo+3nOJUax8lEZYVzS/O4k2zC2JQ1cjCdTb1uFhYkj3kuZr2fgDmSItZJDFjaNnU0wea8Po1i0uzx35RCpBgFknB5w9wtKmXW9bO4pvXL4p1OeMSXpfc3DP8+MhTrX0AzEmBGagitW1cUDTQ07W4NCfG1cQHCWaRFGra+3H7Agn1jrsoy4pBnTs5arCa9n4sJgNlebJ2WSS3DaFlUxajgTlFMnQDEswiSRxu7AUS6x232WigKMtKc4Szm2va+qguyEiJpSEitRVkWllZkYvRoIZsZ5vKJJhFUjjU2IPFlHjvuEty0iK2mE+19XPRzKwYVCTE9PvZLauIvGgwNcnbE5EUDjX2srAkK+Hecc/Mtg0bY/774RZq2/tZWpYbm6KEmGbF2TZmZCf/VpvjlVi/xYSIQGvN4abehBpfDivJGRrMdZ0OvvD7vSwpy+aOy6tiV5gQImbGDGalVJFS6m6l1LcHPbZJKbVXKTXsLY5Sqlgp9Wel1KtKqd9Gu2Ahzne4qZduh5eVFYm3ZeXMHBt2tw+7y4vHF+BTj+5BAz953yqspvhady2EmB7jGWO+DzgJpAMopW4ELgFGOq/uXuBbWusD0ShQiLH87VALBgVXX1Qc61ImLLyW+XiLnb/sa2JffQ8/u2UVlQXpMa5MCBErYwaz1vo2pdRG4LrQ55uBzUqpy86/VimVBxQA31BKlQEPaK0fiWbBQoT9+vUznGixs722k9Wz8hNyP+n184ooyrLysV/voc3u5o7LqrluSUmsyxJCxFC0x5hnA/OBTwLXAB9TSkU8004pdadSapdSaldbW1uUyxCp4LlDzfzqtTMcbbZzzeIZsS5nUvIzLPzwvSvo6HOzvCKXr75lYaxLEkLEWLSXS/mA7VrrDgCl1MvAXKDp/Au11g8ADwCsXr1aZsqLCXN6/FhNBiwmA9cuTtxW5ro5hTz5qcupyE/HYpL5mEKkumj/FjgOLFZKZSqljMDq0GNCRJ3D42f9vEL2fPPNVOQn9pjskrIcckY4h1YIkVqi0mJWSq0B5mitH1NK3QW8QLD1/HOtdUs0voYQ53N6/aRZTJgTbO2yEEKMZlzBrLXeAmw577GNgz7eAewIfbwZ2Byd8oQYmcPjI90sS4qEEMlFmhoiYTk8ftIsEsxCiOQiwSwSltPjJ12CWQiRZCSYRULy+AL4AlqCWQiRdCSYRUJyevwApFnkgDQhRHKRYBYJyeH1AUiLWQiRdCSYRUJyhFrMEsxCiGQjwSwS0kBXtiyXEkIkGQlmkZDOtZhljFkIkVwkmEVCcniCY8yyjlkIkWwkmEVCcsoYsxAiSUkwi4Qkk7+EEMlKglkkJIc3vI5ZglkIkVwkmEVCcnrC65hl8pcQIrlIMIuE5JDlUkKIJCXBLBKS0+PHajJgNKhYlyKEEFElwSwSkkNOlhJCJCkJ5gTk8vr58K92cbChJ9alxEwwmGV8WQiRfCSYE9CJlj6eP9LCQ9tqYl1KzDi9PpmRLYRIShLMCaimvQ+Avx1uGdhoI9U4PH6Z+CWESEoSzAnodLsDCIbT80daYlxNbDg8fmkxCyGSkgRzAqpt72Nmjo2SbBtP7W+MdTkx4ZTJX0KIJCWzZxJQbYeD2UUZlGSnseVYK1prlEqtZUMOj48KS1qsyxBCiKiTFnOC0VpT29ZHdWEGKytz6ej3UNfpjHVZ087p8ZNmlveVQojkI8GcYLocXnpdPqoKgsEM8EZdF009TgIBHdvippHTK13ZQojkJMGcYGrb+wGoLsxgwYws0sxGfvP6WS6/90V+s/1MjKubPrLBiBAiWUkwJ5hTbcGlUlWFGZiMBpaW57DjdCf+gOY328+idfK2mnscXl492c6DW2tw+wIyK1sIkZRkkC6BOD1+frrlFGW5aczKTwdgZWUuO2o7WVOVz47TnRxq7GVJWU6MK42uVruLOx7eycGG3oHHZubYWFOdH8OqhBBiakgwJ5B7nz1KbXs/j37kUkzGYGfHLZfOIifNzM2XVHLpd1/gD7vqkiqY7S4vH/7VLk619vOlaxewtCyHxaXZFGRaY12aEEJMCenKThCvnGzn4VdP88F1VaybUzjweEV+Op/YOJe8DAvXLi5h895GXN7Y7wb2yOtnaO5xXdA9XjrexlX3vcTBhh5+dPNKPnnlXDbML5JQFkIkNQnmBNDr8vLlP+5ndmEGX7lu4YjX/fOqcnqc3pjvBtbU4+Sbmw/ys5dOTfoegYDm648fIMtm4vFPXMamRTOiWKEQQsQvCeYE8O2/HKapx8l9714+6oSny+YWUppj4/e76qexuuHOdgS3DP3boeYxJ6P5A5rG7uHrsF+r6aCh28m/XD2PFRW5U1GmEELEpTGDWSlVpJS6Wyn17UGPbVJK7VVK2SJc/wul1KtKqS1Kqe9Fu+BU8/zhFv6wu55PbJzLysq8Ua81GhTvXFXOthNtEcNuNNFcA13XFfzajT0uDjUGJ2z1uX08d6iZfXXdQ659an8jl937D14+0T7k8T/sqiPLZuLaxSVRq0sIIRLBeFrM9wFuwAyglLoRuBLwjHB9LvAWrfVGrfWXo1Bjyurs9/DVxw9w0cxsPnP1vHG95l2rytEaHt8z/lbzwYYeVt31d5471DzZUoc42+lAKTAo+N5zx7jloe2s/H9/46OP7Ob2h3fi8PgGrt1X14PW8JU/7cfu8gLB7TafPdTMPy0vxSYnSAkhUsyYway1vg3YOujzzVrrbwCOEV6SBfSO8JwYJ601/7r5AD1OD//57uVYTOMbdZhVkMGl1fn8cXf9uNY0n2y186Ff7aTL4WX3ma4LLRuA+k4HJdk21s4uYOvxNlp6XdxxWTV33biEzn4P33v2GLf+Yjs7ajs50WqnMNNCU4+Tu546AsBrpzpweQO8denMqNQjhBCJZCqWS2lgi1LKDXxba70t0kVKqTuBOwEqKyunoIzE9uS+Rp4+0MyXr1vARTOzJ/Taf15dwRf/sI8dtZ1cOrsg4jV1nQ5++MIJHt9TT4bVRGGmlZq2/miUTl2Xg4r8dH76/lXY3V7K89IHnvvr/iYefvU0ADOybRxrtrNhfhEzsm38dMsprltSwkvH20gzG1ldNXrXvRBCJKOoT/7SWl+rtb4C+BDw41Gue0BrvVprvbqoqCjaZSQ0h8fHt544xMrKXD66Yc6EX//WpSXkpJl5cFvNsOdael18c/NBrrpvC0/ua+SOy6rZ8sWNrJqVy+mO6ATz2U4HFXnp5KSbh4QywNffehGbLipmRUUuW4610Wp3s2BGFp/dNI8FM7L4yp/288KRVtbNKcBqkm5sIUTqiXowK6XCrfAuwBvt+6eCxm4nPU4vH1xXhdEw8eMc0y0mbr+siuePtHKk6dyowv+9dpoN33uRx3ac5d2rK9j6pSv51+sXUZBppbowkzMd/fgvcBKYy+unpddNZX56xOeXlufw0Acu4fplM2nvcwMwf0YWVpOR+969nM5+Dw3dTq5YIG/WhBCpKSrBrJRao5S6OfTps0qpLcAzwNejcf9U0+sKTo7KtpknfY8Prqsi02oaaDW32l3c9dcjrK7K4x9f2MjdNy2lJOfcpPrqwnS8fk1D14UdIdkQmg1ekT/6WcmXVJ3bTnPejEwAlpTl8Jmr52E0KK5cUHxBdQghRKIa1xiz1noLsOW8xzYO+ngHsCP08aaoVZei+kLBnGmb/BSA3HQLa2cXcDi0XOkX22rx+QPcfeNSKguGt2arC4PhWNPeF/H58TrbGZwTOFKLOWxxaTbpFiMKKMs9F+Kfvmou77mkghnZw1biCSFESpANRuKQPRTMWRcQzADleWnUdzlxeHz8+vUzXL+slKrCjIjXVoceP91+YePMJ1uCp1/NKoj8dcJMRgPr5xWyojIXpc511yulJJSFEClNDrGIQ+H1vFkX0JUNwWDuc/vYfaaLfo9/1OVHhZkWsqymgfOeJ2vriTbmFGVQlDX2ftb3v2clgSQ+plIIISZDWsxxqM8d6sq2Xtj7pnAX8bbQrlpzikZuxSqlqCrMoGacwez0+Ietk3Z5/eyo7WTD/PFN3EqzGMm4wL+jEEIkG/mtGIfCk78uNJjDS5W2nWjHoBhz7Li6MIM9Z8feZGRvXTc3P/A65XlpvO/SSt6xspycdDM7ajtx+wLjDmYhhBDDSTDHIbvLS6bVNKmlUoOV5QVbzEeaeqnMTx9zXXB1YQZ/2d+I2+cf8dpWu4s7/28X+RkW0i1G/uMvh7nnmaO8bdlMWnpdWEwG1lZH3tRECCHE2CSY45Dd5bvgiV8Aeelm0sxGnF7/wOSu0cwuykDr4OlQ82ZkRbzm6f1NtNrdPPXpy1lSlsPBhh4e3XGWJ/c20uf2ccPy0lFPwBJCCDE6CeY41OfyXXA3NgTHjcvz0jjR2jeuYK4KzaSuae8fMZjb+zwYFCwKbRO6pCyH79y0lLvevgRN8OAKIYQQkyeTv+KQ3e2NSosZznVnjzbxK6xqHEumOvo95GdYMJyXwAaDwmhQQ5Y+CSGEmDgJ5jgU7Mq+sKVSYeGZ2eENREaTk2amMNMy6pKpzn43+RmWqNQmhBBiOAnmC/T7nXVcdd8WfP5A1O7Z5/Jd0K5fg4V34JpTPHaLGYITwEZbMtXR55FgFkKIKSRjzBfA6w/wX88fp6nHRVOPi4oxtqEcr16Xj+woBfN7LqmgPC+dmTmj710dVlWQwZbjbSM+39nv4aLSiR1DKYQQYvykxXwB/rKvkaYeFxA83zha7C5v1Lqyc9MtvG3ZyDt+na+6KIM2u5seZ+SDwTr6PRRIi1kIIaaMBPMkaa35+Us1A1tP1nVFJ5g9vgBuX4CsGO2IdXFlHgCv13QMe87rD9Dj9EpXthBCTCEJ5knacryNYy12vnTNAowGRV3nhR2XGDawHWeUurIn6uLKPDKtJl6K0J3d1e8BoCBz7H2whRBCTI4E8yT9/KVTzMyxcePKMmbm2KLWYo7WARaTZTEZWDengJeOtQ3bC7sjHMzSYhZCiCkjwTwJ++q6eb2mkw9dXo3FZKAiLz1qY8zROvLxQlyxoIiGbien2obOzu4MBbN0ZQshxNSRYJ6EB7bWkGUz8d41lQBU5KdR1+XkE7/ZzXefPnJB9x4I5hieurRhXvAQiq3ndWe397mB4BGRQgghpoYE8wSdbu/nmYNN3Lp21sC2mRV56bTZ3Tx9oJmn9jdd0P1j3ZUNUJGfzuyijGHjzOdazDLGLIQQU0WCeYL+/EYDAB9cVzXw2OD1yw3dTpp6Rp4I1tHn5rlDzSM+Hw9d2QBXzC/i9ZoOXF7/wGOd/cF9snPTYvemQQghkp0E8wQdaeqlqjCD4mzbwGMV+UP3o959ZuQzjX+7s46PPrKb5tD65/OdazHHPpjdvgDbazsHHmvvi7xPthBCiOiRYJ6gYy12FpYMPXlpYUk26+YUcN+7V2AzG0YN5nAg76vvjvj8jtOd5KabyYlxq3Tt7AKsJgMvHTvXnS37ZAshxNSTYJ4Ah8fH2U4HC2YM3ZIyw2ri0Y+sZUVFLsvKc9kzSjC32kPBXNc97Ln2Pjd/P9zCOy8ux2SM7f8am9nIpbMLeOl468Bjnf0eCmR8WQghplRKB/Mjr5/h2YPjn6x1oqUPrWFBycgnNV1cmcehxl48vsiHWrTZgzObI7WY/7i7Hq9fc/OainHXNJWumF/Eqbb+gaVgHX0e8mVGthBCTKmUDeZel5dvP3WYL/9x/4j7Qp/vWLMdgAUlIx/iUJGfhi+g6eh3R3y+LbTkaH9dD4GAJhDQvHisldt/uYN7nz3KpdX5zC3Oivja6XbF/NCyqRPB7mzZJ1sIIaZeygbzcweb8fgC9Lp8PLi1ZlyvOdpsx2Y2DBylGElRaLvKcMt4MK01bXY3BRkW7G4f9zx7lKvu28Ltv9zJwcZePnPVPH56y6rJ/YWmwJyiDMpy03jpWNvAPtnSlS2EEFMrZYP5yX2NVOan87alM/nfV2oHNs8YzbGWXubPyMI4yqzkwtChFpHuZ3f7cHkDvHnRDCC4UUlBppUfvncFr3zlKj735vlxNblKKcUVC4p45WQ7raE3GtKVLYQQUyslz2Pu6HPz6qkOPn7FHG66uIxnDjbx0y2n+Ob1i0Z93YmWPtaHdsUaSbjF3G73DHsu3IpeO7uAf1pRSkVeetTOcJ4qqyrzeHT72YHJatKVLYQQUyslW8yv1XTgD2g2LZrBnKJM3nlxOY+8fmbUjUHsLi+tdjdzijNGvXdhuCs7Qos5HMxFWVbWzSmM+1AGKMsLrtE+0NADSDALIcRUS8lg3lnbSbrFyOLS4CSuj2yYjccXYNuJ9hFfUxM60GFO0cgzsgHSLEYyraaIY8ytg4I5UZTlhoK5PhTM0pUthBBTKiWDeXttJ6tm5WEOrRUOT+YaaTcugFNtfcDYwQzBQx4ijTGHw7o4gYK5JMeGUrA/tLxL9skWQoiplXLB3O3wcKzFzpqq/IHHbGYjBRkWmkYJ5pq2fowGNeqM7LCiLGvEFnOb3Y3ZqGK+q9dEmI0GZmTZ6HX5ZJ9sIYSYBmMGs1KqSCl1t1Lq24Me26SU2quUso3yuv9SSt0TrUKjZdfpLrSGS6rzhzxekmOjeZQx5lNtfczKT8diGvu9TGGmdcQWc1GmFaUSa6/p8Diz7JMthBBTbzwt5vsAN2AGUErdCFwJDJ92HKKUqgQ2RaG+qNt5uhOL0cCKitwhj8/MsdHcO/KSqZq2fmaPoxsbgi3m9r7h355Wu4ui7BHfy8St0txzwSyEEGJqjRnMWuvbgK2DPt+stf4G4BjlZd8B7r3w8qJve20nyytysJmNQx4frcXsD2hqO/oHTo8aS2GmlR6nF7fv3JGJ/oDmWLOd8lDIJZLS3OCbCdlcRAghpl7Ux5iVUh8CdgP1Y1x3p1Jql1JqV1tb22iXRo3D4+NgQw+XVOUPe25mThpdDu+Q84fDatr68PgC45r4BeeWTHUMajVvPdFGq93N9ctmTrL62Am/mZDNRYQQYupFNZiVUvOBm4AfjnWt1voBrfVqrfXqoqLRN+2IljfOduMLaNZUDw/mklAXc6SZ2Zv3NmBQcMWC8dVZFGH3rz/sqiM/w8LVF82YTOkxFe7KljXMQggx9aK989f7CIb9o0AxUKKU2q61/nOUv86kbK/txKBg1ay8Yc/NzAkGc1OPi6rCc13W/oDmT7sbuGJ+ETPGOT5cGGpZ/s8/TmI2GWjucbG3rpsPvKlqXJPH4s25YJaubCGEmGpRCWal1Bpgjtb63wc9thG4Ll5CGWBHbQeLSrPJsg1f8lMSCubm3qHjzNtOtNHc6+JbN4y+XedgVQUZZFpNbD3RRmlOGiU5Nt6xsowPr6++sL9AjMwqSGdmjo0lZSOfqiWEECI6xhXMWustwJbzHts46OMdwI6xXhNLbp+fN8528/5LZ0V8vmRQi3mw12s6MRsVV19UPO6vlZdhYe+33ozRoBJuaVQk6RYTr33t6liXIYQQKSFlDrE42NCD2xeIOL4MwfDJSTMPG2Nu6HYyMycNq8kY8XUjMRkTr8taCCFE7KVMemyv7QTgkqrh48thVQXp7DnbhdZ64LHGbufAftFCCCHEVEuZYN5R28nc4kwKMkeewPTuSyo42NDLztNdA481dDkHJj8JIYQQUy0lgtkf0Ow+3TViN3bYO1aWk5du5sFtNQB4/QFa7K6BLSmFEEKIqZYSwVzb3o/d7ePiypG7sSF4ZOOta2fx/JEWatv7ae5xoTWU5SbeNppCCCESU0oEc6/LC4zvLOFb3jQLs8HA/75cS31XcOlUWe7YJ0oJIYQQ0ZASs7KdnuA2m+nmsWdWF2fZePuKUv6wu25goxHpyhZCCDFdUqLF3O/2AZBhHd/7kA+vn43LG+CnW04C53YFE0IIIaZaSgSzI9xitoxvLfKCkizWzyukvc9DYaZ12ElUQgghxFRJqWAeb4sZ4CPrZwMy8UsIIcT0SokxZocn2JWdNs4WM8D6eYUsr8hlcansDy2EEGL6pEQw97vHP/krTCnFHz/2JkyGxN/rWgghROJIiWB2eHxYTYYJ719tlv2uhRBCTLOUSB6Hxz/uiV9CCCFELKVEMPd7fKRbUqJzQAghRIJLiWB2uP1kWKXFLIQQIv6lRjB7/aRJi1kIIUQCSI1gdvvIkDFmIYQQCSAlgrnf45cxZiGEEAkhJYLZ6fHJGLMQQoiEkBLB3C/LpYQQQiSIlAhmh1uWSwkhhEgMSR/MWmscXr9M/hJCCJEQkj6YXd4AWiPLpYQQQiSEpA/m/tDJUjL5SwghRCJI+mB2hE+WkhazEEKIBJD8wewNtZhljFkIIUQCSPpgDp/FnCbBLIQQIgEkfTA7BsaYpStbCCFE/EuBYA6PMUuLWQghRPxLgWAOtphl8pcQQohEMGYwK6WKlFJ3K6W+PeixTUqpvUopW4Trv6eU+odSaqdS6qpoFzxR4TFmmfwlhBAiEYynGXkfcBJIB1BK3QhcAnhGuP7bWmu7UqoC+AXwjyjUOWnOcFe2jDELIYRIAGO2mLXWtwFbB32+WWv9DcAxwvX20IfzgP3RKPJC2F1eANLM0mIWQggR/6LejFRKvRm4F8gA3jbKdXcCdwJUVlZGu4wBx1v6qC7MwGhQU/Y1hBBCiGiJ+uQvrfXftdYXA9cAj45y3QNa69Va69VFRUXRLmPAwcYeFpdmT9n9hRBCiGiKajArpUxKqfTQp+3Rvv9EdTs81Hc5WVKWE8syhBBCiHGLSle2UmoNMAd4EviLUiocyF+Lxv0n62BDLwBLSiWYhRBCJIZxBbPWeguw5bzHNg76eAewI/RpzJdIhR1s7AGQrmwhhBAJI+k2GHl8Tz23/e8OtNYcaOihLDeNvAxLrMsSQgghxiXpgllr2Hq8jecONbO9poNl5dKNLYQQInEkXTDfsLyUGdlWPvu7vbT3efjQ5dWxLkkIIYQYt6QLZovJwAfXVePyBnjzohmsrsqPdUlCCCHEuCXlPpW3rK3kVFsfn7lqXqxLEUIIISYkKYM5y2bmB/+8PNZlCCGEEBOWdF3ZQgghRCKTYBZCCCHiiASzEEIIEUckmIUQQog4IsEshBBCxBEJZiGEECKOSDALIYQQcUSCWQghhIgjEsxCCCFEHJFgFkIIIeKIBLMQQggRRySYhRBCiDgiwSyEEELEEaW1jnUNKKXagDMXcItCoD1K5UyleKwzHms6X7zXGO/1hcV7nfFeHyRGjRD/dcZ7fTD1Nc7SWhdFeiIugvlCKaV2aa1Xx7qOscRjnfFY0/nivcZ4ry8s3uuM9/ogMWqE+K8z3uuD2NYoXdlCCCFEHJFgFkIIIeJIsgTzA7EuYJzisc54rOl88V5jvNcXFu91xnt9kBg1QvzXGe/1QQxrTIoxZiGEECJZJEuLWQghhEgOWuuY/QFygd8CW4CtQDWwAHgBeAX4/kjXDbrHJmAvYBvl63w89LrtwBWDHl8DvAgsjNc6gStDNb4O/E+c1LQJeB7YAfwgHr9vg55bDjTFW33AeqAmdM8tQH68fh+BrxP8+XsFWBxP9QFPDfoeHgb+M96+h0AO8DjBf8e/Bczx+P8aqACeBrYBjwLWGNaXBXwBeGjQYyWh/9/bgIdH+j7GssbQ4+PKldH+TOpF0foDlAKloY/fBvwYeAaoCj32B+DSSNeFPr4RuJtgQET8BgKzQj9sCpgB7Ag9vhb4Ueh/9FjBHMs6LwYMg77OJXFQU9aga54P3z+evm+Dnv81cCje6gNuAP4lAf6dvAX4f/Fa33nX/B6oiLcagc8AHw59fBfwznj8XgKPAasG1XlHLOoLXXc/8Fngt4Me+wWwLvTx94H3xOp7OEqN486V0f7EtCtba92otW4MfdoFuAl+I06HHvsT8KYI1/WHXr9Za/0NwDHKl9kE/EEHtQCdSqlcrfXrWutPM44F5DGuc4/WOhDhnrGsyQ6glMoG/EBHpBfHssZQff8E7AHscVhfbuheY4pxnbcDLqXUVqXUQ0qptDirDwCl1DqgXmtdF+nFMa7RDuSHrilglN85Ma6zSmu9O3TNX4BLYlQfWuvPApvPe3iB1vrVwV9nhNfGrMaJ5Mpo4mKMWSlVBnwRuI+hv+Q7gLwI190/gdsXA20j3TNR6lRK3QS4tNaH46EmpdQW4ATwuNbaPdpNYlGjUqqEYHfdf491gxh9D63AZ5RSryilvjmeG8WozrkEexw2AMeAT8RZfWFfGM/9YlTjH4FblVKHgfkEu1Pjsc7TSqmrQ49dBZhiVN9IBufVmL/HY1RjVIz4jZ8uSqnrCXbrfYTgO5TcQU/nEfoBGnyd1jpiCy103Rrge6FPfwr0MPR/4MA9E6FOpZSZYLfSGa31Z+KhJgCt9UallAV4SCl1TGu9ZYR7xqLGduAR4Ataa59SaqTbxex7qLV+iOD3zgw8qJR6q9b66XirE9AEu+UI/feLcVYfSqlSgitMzo50vxjX+CDwfq31fqXUDcB3gC/HYZ2fB36slPoSwZ6m07GoT2v9u5EujfR14qzG6NCT7AOPxh9gGfDz8x7bBpSFPv4tcFGk6857zRZGHk9ZCmwOfVwM/O285x9m7DHmmNUJ3Mt5E5rioKacQdf8ALg+nr5vwArg1dD9f0swqO+Pl/pCH5sGXXM/8NY4/fn7CfC20McfJ8K4eCzrC33+OeDWke4b6xqBl4GS0Mergd/HY52DnjcSfGNbHYv6Bl1TxdDx2z8CF4c+vhe4Llbfw5FqHPT4w1zAGHOsW8zXAetD3aIAZwm+a/ujUsoNPKm1PqKU+vL512mtbxvPF9BaH1BKvaGUehVwEhysT6Q6rwcuHdTqe0Br/WiMa/pcqMsrQHBW519HuEVMatRaHwDWha9RSr2ug+NBcVFf6KnPKKVuJNg99zrBySkjiWWd/w94ONSKqgc+HGf1AWwkGM6jiWWNXwJ+r5TyE+yB+Hg81qmUej/BoQoD8BOtdW0s6hvFV4D/VUoFgJ3AcyNcF8sao0I2GBFCCCHiSFxM/hJCCCFEkASzEEIIEUckmIUQQog4IsEshBBCxBEJZiGEECKOSDALIYQQcUSCWQghhIgjEsxCCCFEHPn/YMU5oSHFTLQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = '카카오'\n",
    "fromdate = str(20210101)\n",
    "todate = str(20211104)\n",
    "\n",
    "ticker1 = stock_list.loc[stock_list['종목명']== name, '종목코드']\n",
    "df1 = stock.get_market_ohlcv_by_date(fromdate=fromdate, todate=todate, ticker=ticker1)\n",
    "\n",
    "data = np.log(df1['종가'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(data)\n",
    "plt.legend([f'{name}'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seri = df1['종가']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종가</th>\n",
       "      <th>일계도</th>\n",
       "      <th>이계도</th>\n",
       "      <th>일계도부호</th>\n",
       "      <th>이계도부호</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>날짜</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>79483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>78881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>79383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>80788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08</th>\n",
       "      <td>87111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               종가  일계도  이계도 일계도부호 이계도부호\n",
       "날짜                                     \n",
       "2021-01-04  79483  NaN  NaN   NaN   NaN\n",
       "2021-01-05  78881  NaN  NaN   NaN   NaN\n",
       "2021-01-06  79383  NaN  NaN   NaN   NaN\n",
       "2021-01-07  80788  NaN  NaN   NaN   NaN\n",
       "2021-01-08  87111  NaN  NaN   NaN   NaN"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(seri, columns=['종가','일계도','이계도','일계도부호','이계도부호'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghdak\\AppData\\Local\\Temp/ipykernel_8380/829604211.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['일계도'][0] = 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종가</th>\n",
       "      <th>일계도</th>\n",
       "      <th>이계도</th>\n",
       "      <th>일계도부호</th>\n",
       "      <th>이계도부호</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>날짜</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>79483</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>78881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>79383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>80788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08</th>\n",
       "      <td>87111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               종가  일계도  이계도 일계도부호 이계도부호\n",
       "날짜                                     \n",
       "2021-01-04  79483    0  NaN   NaN   NaN\n",
       "2021-01-05  78881  NaN  NaN   NaN   NaN\n",
       "2021-01-06  79383  NaN  NaN   NaN   NaN\n",
       "2021-01-07  80788  NaN  NaN   NaN   NaN\n",
       "2021-01-08  87111  NaN  NaN   NaN   NaN"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['일계도'][0] = 0\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghdak\\AppData\\Local\\Temp/ipykernel_8380/3311632609.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['일계도'][i] = df['종가'][i] - df['종가'][i-1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종가</th>\n",
       "      <th>일계도</th>\n",
       "      <th>이계도</th>\n",
       "      <th>일계도부호</th>\n",
       "      <th>이계도부호</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>날짜</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>79483</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>78881</td>\n",
       "      <td>-602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>79383</td>\n",
       "      <td>502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>80788</td>\n",
       "      <td>1405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08</th>\n",
       "      <td>87111</td>\n",
       "      <td>6323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               종가   일계도  이계도 일계도부호 이계도부호\n",
       "날짜                                      \n",
       "2021-01-04  79483     0  NaN   NaN   NaN\n",
       "2021-01-05  78881  -602  NaN   NaN   NaN\n",
       "2021-01-06  79383   502  NaN   NaN   NaN\n",
       "2021-01-07  80788  1405  NaN   NaN   NaN\n",
       "2021-01-08  87111  6323  NaN   NaN   NaN"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1, len(seri)):\n",
    "    df['일계도'][i] = df['종가'][i] - df['종가'][i-1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghdak\\AppData\\Local\\Temp/ipykernel_8380/3300555474.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['이계도'][0] = 0\n",
      "C:\\Users\\ghdak\\AppData\\Local\\Temp/ipykernel_8380/3300555474.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['이계도'][i] = df['일계도'][i] - df['일계도'][i-1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종가</th>\n",
       "      <th>일계도</th>\n",
       "      <th>이계도</th>\n",
       "      <th>일계도부호</th>\n",
       "      <th>이계도부호</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>날짜</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>79483</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>78881</td>\n",
       "      <td>-602</td>\n",
       "      <td>-602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>79383</td>\n",
       "      <td>502</td>\n",
       "      <td>1104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>80788</td>\n",
       "      <td>1405</td>\n",
       "      <td>903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08</th>\n",
       "      <td>87111</td>\n",
       "      <td>6323</td>\n",
       "      <td>4918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               종가   일계도   이계도 일계도부호 이계도부호\n",
       "날짜                                       \n",
       "2021-01-04  79483     0     0   NaN   NaN\n",
       "2021-01-05  78881  -602  -602   NaN   NaN\n",
       "2021-01-06  79383   502  1104   NaN   NaN\n",
       "2021-01-07  80788  1405   903   NaN   NaN\n",
       "2021-01-08  87111  6323  4918   NaN   NaN"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['이계도'][0] = 0\n",
    "for i in range(1, len(seri)):\n",
    "    df['이계도'][i] = df['일계도'][i] - df['일계도'][i-1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghdak\\AppData\\Local\\Temp/ipykernel_8380/2770070508.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['일계도부호'][i] = 1\n",
      "C:\\Users\\ghdak\\AppData\\Local\\Temp/ipykernel_8380/2770070508.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['일계도부호'][i] = 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    if df['일계도'][i] >= 0:\n",
    "        df['일계도부호'][i] = 1\n",
    "    else:\n",
    "        df['일계도부호'][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghdak\\AppData\\Local\\Temp/ipykernel_8380/3065516705.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['이계도부호'][i] = 1\n",
      "C:\\Users\\ghdak\\AppData\\Local\\Temp/ipykernel_8380/3065516705.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['이계도부호'][i] = 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    if df['이계도'][i] >= 0:\n",
    "        df['이계도부호'][i] = 1\n",
    "    else:\n",
    "        df['이계도부호'][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종가</th>\n",
       "      <th>일계도</th>\n",
       "      <th>이계도</th>\n",
       "      <th>일계도부호</th>\n",
       "      <th>이계도부호</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>날짜</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>79483</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>78881</td>\n",
       "      <td>-602</td>\n",
       "      <td>-602</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>79383</td>\n",
       "      <td>502</td>\n",
       "      <td>1104</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>80788</td>\n",
       "      <td>1405</td>\n",
       "      <td>903</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08</th>\n",
       "      <td>87111</td>\n",
       "      <td>6323</td>\n",
       "      <td>4918</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-11</th>\n",
       "      <td>90924</td>\n",
       "      <td>3813</td>\n",
       "      <td>-2510</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-12</th>\n",
       "      <td>91827</td>\n",
       "      <td>903</td>\n",
       "      <td>-2910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-13</th>\n",
       "      <td>91225</td>\n",
       "      <td>-602</td>\n",
       "      <td>-1505</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-14</th>\n",
       "      <td>90623</td>\n",
       "      <td>-602</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-15</th>\n",
       "      <td>87813</td>\n",
       "      <td>-2810</td>\n",
       "      <td>-2208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               종가    일계도    이계도 일계도부호 이계도부호\n",
       "날짜                                         \n",
       "2021-01-04  79483      0      0     1     1\n",
       "2021-01-05  78881   -602   -602     0     0\n",
       "2021-01-06  79383    502   1104     1     1\n",
       "2021-01-07  80788   1405    903     1     1\n",
       "2021-01-08  87111   6323   4918     1     1\n",
       "2021-01-11  90924   3813  -2510     1     0\n",
       "2021-01-12  91827    903  -2910     1     0\n",
       "2021-01-13  91225   -602  -1505     0     0\n",
       "2021-01-14  90623   -602      0     0     1\n",
       "2021-01-15  87813  -2810  -2208     0     0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cedabc6400>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df['종가'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종가</th>\n",
       "      <th>일계도</th>\n",
       "      <th>이계도</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>날짜</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>79483</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>78881</td>\n",
       "      <td>-602</td>\n",
       "      <td>-602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>79383</td>\n",
       "      <td>502</td>\n",
       "      <td>1104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>80788</td>\n",
       "      <td>1405</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08</th>\n",
       "      <td>87111</td>\n",
       "      <td>6323</td>\n",
       "      <td>4918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-11</th>\n",
       "      <td>90924</td>\n",
       "      <td>3813</td>\n",
       "      <td>-2510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-12</th>\n",
       "      <td>91827</td>\n",
       "      <td>903</td>\n",
       "      <td>-2910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-13</th>\n",
       "      <td>91225</td>\n",
       "      <td>-602</td>\n",
       "      <td>-1505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-14</th>\n",
       "      <td>90623</td>\n",
       "      <td>-602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-15</th>\n",
       "      <td>87813</td>\n",
       "      <td>-2810</td>\n",
       "      <td>-2208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               종가    일계도    이계도\n",
       "날짜                             \n",
       "2021-01-04  79483      0      0\n",
       "2021-01-05  78881   -602   -602\n",
       "2021-01-06  79383    502   1104\n",
       "2021-01-07  80788   1405    903\n",
       "2021-01-08  87111   6323   4918\n",
       "2021-01-11  90924   3813  -2510\n",
       "2021-01-12  91827    903  -2910\n",
       "2021-01-13  91225   -602  -1505\n",
       "2021-01-14  90623   -602      0\n",
       "2021-01-15  87813  -2810  -2208"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cedac0d400>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df['일계도'][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cedac47220>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df['이계도'][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Model in module tensorflow.python.keras.engine.training:\n",
      "\n",
      "class Model(tensorflow.python.keras.engine.base_layer.Layer, tensorflow.python.keras.utils.version_utils.ModelVersionSelector)\n",
      " |  Model(*args, **kwargs)\n",
      " |  \n",
      " |  `Model` groups layers into an object with training and inference features.\n",
      " |  \n",
      " |  Args:\n",
      " |      inputs: The input(s) of the model: a `keras.Input` object or list of\n",
      " |          `keras.Input` objects.\n",
      " |      outputs: The output(s) of the model. See Functional API example below.\n",
      " |      name: String, the name of the model.\n",
      " |  \n",
      " |  There are two ways to instantiate a `Model`:\n",
      " |  \n",
      " |  1 - With the \"Functional API\", where you start from `Input`,\n",
      " |  you chain layer calls to specify the model's forward pass,\n",
      " |  and finally you create your model from inputs and outputs:\n",
      " |  \n",
      " |  ```python\n",
      " |  import tensorflow as tf\n",
      " |  \n",
      " |  inputs = tf.keras.Input(shape=(3,))\n",
      " |  x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
      " |  outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
      " |  model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
      " |  ```\n",
      " |  \n",
      " |  2 - By subclassing the `Model` class: in that case, you should define your\n",
      " |  layers in `__init__` and you should implement the model's forward pass\n",
      " |  in `call`.\n",
      " |  \n",
      " |  ```python\n",
      " |  import tensorflow as tf\n",
      " |  \n",
      " |  class MyModel(tf.keras.Model):\n",
      " |  \n",
      " |    def __init__(self):\n",
      " |      super(MyModel, self).__init__()\n",
      " |      self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
      " |      self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
      " |  \n",
      " |    def call(self, inputs):\n",
      " |      x = self.dense1(inputs)\n",
      " |      return self.dense2(x)\n",
      " |  \n",
      " |  model = MyModel()\n",
      " |  ```\n",
      " |  \n",
      " |  If you subclass `Model`, you can optionally have\n",
      " |  a `training` argument (boolean) in `call`, which you can use to specify\n",
      " |  a different behavior in training and inference:\n",
      " |  \n",
      " |  ```python\n",
      " |  import tensorflow as tf\n",
      " |  \n",
      " |  class MyModel(tf.keras.Model):\n",
      " |  \n",
      " |    def __init__(self):\n",
      " |      super(MyModel, self).__init__()\n",
      " |      self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
      " |      self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
      " |      self.dropout = tf.keras.layers.Dropout(0.5)\n",
      " |  \n",
      " |    def call(self, inputs, training=False):\n",
      " |      x = self.dense1(inputs)\n",
      " |      if training:\n",
      " |        x = self.dropout(x, training=training)\n",
      " |      return self.dense2(x)\n",
      " |  \n",
      " |  model = MyModel()\n",
      " |  ```\n",
      " |  \n",
      " |  Once the model is created, you can config the model with losses and metrics\n",
      " |  with `model.compile()`, train the model with `model.fit()`, or use the model\n",
      " |  to do prediction with `model.predict()`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Model\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      tensorflow.python.keras.utils.version_utils.LayerVersionSelector\n",
      " |      tensorflow.python.keras.utils.version_utils.ModelVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *args, **kwargs)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Builds the model based on input shapes received.\n",
      " |      \n",
      " |      This is to be used for subclassed models, which do not know at instantiation\n",
      " |      time what their inputs look like.\n",
      " |      \n",
      " |      This method only exists for users who want to call `model.build()` in a\n",
      " |      standalone way (as a substitute for calling the model on real data to\n",
      " |      build it). It will never be called by the framework (and thus it will\n",
      " |      never throw unexpected errors in an unrelated workflow).\n",
      " |      \n",
      " |      Args:\n",
      " |       input_shape: Single tuple, TensorShape, or list/dict of shapes, where\n",
      " |           shapes are tuples, integers, or TensorShapes.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError:\n",
      " |          1. In case of invalid user-provided data (not of type tuple,\n",
      " |             list, TensorShape, or dict).\n",
      " |          2. If the model requires call arguments that are agnostic\n",
      " |             to the input shapes (positional or kwarg in call signature).\n",
      " |          3. If not all layers were properly built.\n",
      " |          4. If float type inputs are not supported within the layers.\n",
      " |      \n",
      " |        In each of these cases, the user should build their model by calling it\n",
      " |        on real tensor data.\n",
      " |  \n",
      " |  call(self, inputs, training=None, mask=None)\n",
      " |      Calls the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      Note: This method should not be called directly. It is only meant to be\n",
      " |      overridden when subclassing `tf.keras.Model`.\n",
      " |      To call a model on an input, always use the `__call__` method,\n",
      " |      i.e. `model(inputs)`, which relies on the underlying `call` method.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          training: Boolean or boolean scalar tensor, indicating whether to run\n",
      " |            the `Network` in training mode or inference mode.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, steps_per_execution=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      Args:\n",
      " |          optimizer: String (name of optimizer) or optimizer instance. See\n",
      " |            `tf.keras.optimizers`.\n",
      " |          loss: String (name of objective function), objective function or\n",
      " |            `tf.keras.losses.Loss` instance. See `tf.keras.losses`. An objective\n",
      " |            function is any callable with the signature `loss = fn(y_true,\n",
      " |            y_pred)`, where y_true = ground truth values with shape =\n",
      " |            `[batch_size, d0, .. dN]`, except sparse loss functions such as sparse\n",
      " |            categorical crossentropy where shape = `[batch_size, d0, .. dN-1]`.\n",
      " |            y_pred = predicted values with shape = `[batch_size, d0, .. dN]`. It\n",
      " |            returns a weighted loss float tensor. If a custom `Loss` instance is\n",
      " |            used and reduction is set to NONE, return value has the shape\n",
      " |            [batch_size, d0, .. dN-1] ie. per-sample or per-timestep loss values;\n",
      " |            otherwise, it is a scalar. If the model has multiple outputs, you can\n",
      " |            use a different loss on each output by passing a dictionary or a list\n",
      " |            of losses. The loss value that will be minimized by the model will\n",
      " |            then be the sum of all individual losses.\n",
      " |          metrics: List of metrics to be evaluated by the model during training\n",
      " |            and testing. Each of this can be a string (name of a built-in\n",
      " |            function), function or a `tf.keras.metrics.Metric` instance. See\n",
      " |            `tf.keras.metrics`. Typically you will use `metrics=['accuracy']`. A\n",
      " |            function is any callable with the signature `result = fn(y_true,\n",
      " |            y_pred)`. To specify different metrics for different outputs of a\n",
      " |            multi-output model, you could also pass a dictionary, such as\n",
      " |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
      " |                You can also pass a list (len = len(outputs)) of lists of metrics\n",
      " |                such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
      " |                `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
      " |                strings 'accuracy' or 'acc', we convert this to one of\n",
      " |                `tf.keras.metrics.BinaryAccuracy`,\n",
      " |                `tf.keras.metrics.CategoricalAccuracy`,\n",
      " |                `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n",
      " |                function used and the model output shape. We do a similar\n",
      " |                conversion for the strings 'crossentropy' and 'ce' as well.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar coefficients\n",
      " |            (Python floats) to weight the loss contributions of different model\n",
      " |            outputs. The loss value that will be minimized by the model will then\n",
      " |            be the *weighted sum* of all individual losses, weighted by the\n",
      " |            `loss_weights` coefficients.\n",
      " |              If a list, it is expected to have a 1:1 mapping to the model's\n",
      " |                outputs. If a dict, it is expected to map output names (strings)\n",
      " |                to scalar coefficients.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted by\n",
      " |            sample_weight or class_weight during training and testing.\n",
      " |          run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
      " |            logic will not be wrapped in a `tf.function`. Recommended to leave\n",
      " |            this as `None` unless your `Model` cannot be run inside a\n",
      " |            `tf.function`. `run_eagerly=True` is not supported when using\n",
      " |            `tf.distribute.experimental.ParameterServerStrategy`.\n",
      " |          steps_per_execution: Int. Defaults to 1. The number of batches to\n",
      " |            run during each `tf.function` call. Running multiple batches\n",
      " |            inside a single `tf.function` call can greatly improve performance\n",
      " |            on TPUs or small models with a large Python overhead.\n",
      " |            At most, one full epoch will be run each\n",
      " |            execution. If a number larger than the size of the epoch is passed,\n",
      " |            the execution will be truncated to the size of the epoch.\n",
      " |            Note that if `steps_per_execution` is set to `N`,\n",
      " |            `Callback.on_batch_begin` and `Callback.on_batch_end` methods\n",
      " |            will only be called every `N` batches\n",
      " |            (i.e. before/after each `tf.function` execution).\n",
      " |          **kwargs: Arguments supported for backwards compatibility only.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid arguments for\n",
      " |              `optimizer`, `loss` or `metrics`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False, **kwargs)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches (see the `batch_size` arg.)\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
      " |            `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
      " |            should not be specified (since targets will be obtained from the\n",
      " |            iterator/dataset).\n",
      " |          batch_size: Integer or `None`. Number of samples per batch of\n",
      " |            computation. If unspecified, `batch_size` will default to 32. Do not\n",
      " |            specify the `batch_size` if your data is in the form of a dataset,\n",
      " |            generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |            batches).\n",
      " |          verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
      " |          sample_weight: Optional Numpy array of weights for the test samples,\n",
      " |            used for weighting the loss function. You can either pass a flat (1D)\n",
      " |            Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples), or in the case of\n",
      " |                temporal data, you can pass a 2D array with shape `(samples,\n",
      " |                sequence_length)`, to apply a different weight to every timestep\n",
      " |                of every sample. This argument is not supported when `x` is a\n",
      " |                dataset, instead pass sample weights as the third element of `x`.\n",
      " |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
      " |            before declaring the evaluation round finished. Ignored with the\n",
      " |            default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
      " |            None, 'evaluate' will run until the dataset is exhausted. This\n",
      " |            argument is not supported with array inputs.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
      " |            callbacks to apply during evaluation. See\n",
      " |            [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |            input only. Maximum size for the generator queue. If unspecified,\n",
      " |            `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |            only. Maximum number of processes to spin up when using process-based\n",
      " |            threading. If unspecified, `workers` will default to 1.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |            threading. If unspecified, `use_multiprocessing` will default to\n",
      " |            `False`. Note that because this implementation relies on\n",
      " |            multiprocessing, you should not pass non-picklable arguments to the\n",
      " |            generator as they can't be passed easily to children processes.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |          **kwargs: Unused at this time.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`.\n",
      " |      \n",
      " |      `Model.evaluate` is not yet supported with\n",
      " |      `tf.distribute.experimental.ParameterServerStrategy`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.evaluate` is wrapped in `tf.function`.\n",
      " |          ValueError: in case of invalid arguments.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Evaluates the model on a data generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.evaluate` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose='auto', callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |            - A `tf.keras.utils.experimental.DatasetCreator`, which wraps a\n",
      " |              callable that takes a single argument of type\n",
      " |              `tf.distribute.InputContext`, and returns a `tf.data.Dataset`.\n",
      " |              `DatasetCreator` should be used when users prefer to specify the\n",
      " |              per-replica batching and sharding logic for the `Dataset`.\n",
      " |              See `tf.keras.utils.experimental.DatasetCreator` doc for more\n",
      " |              information.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given below. If using\n",
      " |            `tf.distribute.experimental.ParameterServerStrategy`, only\n",
      " |            `DatasetCreator` type is supported for `x`.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
      " |            or `keras.utils.Sequence` instance, `y` should\n",
      " |            not be specified (since targets will be obtained from `x`).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: 'auto', 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |              'auto' defaults to 1 for most cases, but 2 when used with\n",
      " |              `ParameterServerStrategy`. Note that the progress bar is not\n",
      " |              particularly useful when logged to a file, so verbose=2 is\n",
      " |              recommended when not running interactively (eg, in a production\n",
      " |              environment).\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See `tf.keras.callbacks`. Note `tf.keras.callbacks.ProgbarLogger`\n",
      " |              and `tf.keras.callbacks.History` callbacks are created automatically\n",
      " |              and need not be passed into `model.fit`.\n",
      " |              `tf.keras.callbacks.ProgbarLogger` is created or not based on\n",
      " |              `verbose` argument to `model.fit`.\n",
      " |              Callbacks with batch-level calls are currently unsupported with\n",
      " |              `tf.distribute.experimental.ParameterServerStrategy`, and users are\n",
      " |              advised to implement epoch-level calls instead with an appropriate\n",
      " |              `steps_per_epoch` value.\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling. This argument is\n",
      " |              not supported when `x` is a dataset, generator or\n",
      " |             `keras.utils.Sequence` instance.\n",
      " |              `validation_split` is not yet supported with\n",
      " |              `tf.distribute.experimental.ParameterServerStrategy`.\n",
      " |          validation_data: Data on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data. Thus, note the fact\n",
      " |              that the validation loss of data provided using `validation_split`\n",
      " |              or `validation_data` is not affected by regularization layers like\n",
      " |              noise and dropout.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |              `validation_data` could be:\n",
      " |                - A tuple `(x_val, y_val)` of Numpy arrays or tensors.\n",
      " |                - A tuple `(x_val, y_val, val_sample_weights)` of NumPy arrays.\n",
      " |                - A `tf.data.Dataset`.\n",
      " |                - A Python generator or `keras.utils.Sequence` returning\n",
      " |                `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n",
      " |              `validation_data` is not yet supported with\n",
      " |              `tf.distribute.experimental.ParameterServerStrategy`.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch'). This argument is ignored\n",
      " |              when `x` is a generator or an object of tf.data.Dataset.\n",
      " |              'batch' is a special option for dealing\n",
      " |              with the limitations of HDF5 data; it shuffles in batch-sized\n",
      " |              chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample. This\n",
      " |              argument is not supported when `x` is a dataset, generator, or\n",
      " |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
      " |              as the third element of `x`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined. If x is a\n",
      " |              `tf.data` dataset, and 'steps_per_epoch'\n",
      " |              is None, the epoch will run until the input dataset is exhausted.\n",
      " |              When passing an infinitely repeating dataset, you must specify the\n",
      " |              `steps_per_epoch` argument. This argument is not supported with\n",
      " |              array inputs. `steps_per_epoch=None` is not supported when using\n",
      " |              `tf.distribute.experimental.ParameterServerStrategy`.\n",
      " |          validation_steps: Only relevant if `validation_data` is provided and\n",
      " |              is a `tf.data` dataset. Total number of steps (batches of\n",
      " |              samples) to draw before stopping when performing validation\n",
      " |              at the end of every epoch. If 'validation_steps' is None, validation\n",
      " |              will run until the `validation_data` dataset is exhausted. In the\n",
      " |              case of an infinitely repeated dataset, it will run into an\n",
      " |              infinite loop. If 'validation_steps' is specified and only part of\n",
      " |              the dataset will be consumed, the evaluation will start from the\n",
      " |              beginning of the dataset at each epoch. This ensures that the same\n",
      " |              validation samples are used every time.\n",
      " |          validation_batch_size: Integer or `None`.\n",
      " |              Number of samples per validation batch.\n",
      " |              If unspecified, will default to `batch_size`.\n",
      " |              Do not specify the `validation_batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          validation_freq: Only relevant if validation data is provided. Integer\n",
      " |              or `collections.abc.Container` instance (e.g. list, tuple, etc.).\n",
      " |              If an integer, specifies how many training epochs to run before a\n",
      " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
      " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up\n",
      " |              when using process-based threading. If unspecified, `workers`\n",
      " |              will default to 1.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      Unpacking behavior for iterator-like inputs:\n",
      " |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
      " |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
      " |        yield not only features (x) but optionally targets (y) and sample weights.\n",
      " |        Keras requires that the output of such iterator-likes be unambiguous. The\n",
      " |        iterator should return a tuple of length 1, 2, or 3, where the optional\n",
      " |        second and third elements will be used for y and sample_weight\n",
      " |        respectively. Any other type provided will be wrapped in a length one\n",
      " |        tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
      " |        should still adhere to the top-level tuple structure.\n",
      " |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      " |        features, targets, and weights from the keys of a single dict.\n",
      " |          A notable unsupported data type is the namedtuple. The reason is that\n",
      " |        it behaves like both an ordered datatype (tuple) and a mapping\n",
      " |        datatype (dict). So given a namedtuple of the form:\n",
      " |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      " |        it is ambiguous whether to reverse the order of the elements when\n",
      " |        interpreting the value. Even worse is a tuple of the form:\n",
      " |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      " |        where it is unclear if the tuple was intended to be unpacked into x, y,\n",
      " |        and sample_weight or passed through as a single element to `x`. As a\n",
      " |        result the data processing code will simply raise a ValueError if it\n",
      " |        encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: 1. If the model was never compiled or,\n",
      " |          2. If `model.fit` is  wrapped in `tf.function`.\n",
      " |      \n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects or when the input data is empty.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Fits the model on data yielded batch-by-batch by a Python generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.fit` now supports generators, so there is no longer any need to use\n",
      " |        this endpoint.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Note that `get_config()` does not guarantee to return a fresh copy of dict\n",
      " |      every time it is called. The callers should make a copy of the returned dict\n",
      " |      if they want to modify it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Args:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None)\n",
      " |      Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
      " |      \n",
      " |      If `by_name` is False weights are loaded based on the network's\n",
      " |      topology. This means the architecture should be the same as when the weights\n",
      " |      were saved.  Note that layers that don't have weights are not taken into\n",
      " |      account in the topological ordering, so adding or removing layers is fine as\n",
      " |      long as they don't have weights.\n",
      " |      \n",
      " |      If `by_name` is True, weights are loaded into layers only if they share the\n",
      " |      same name. This is useful for fine-tuning or transfer-learning models where\n",
      " |      some of the layers have changed.\n",
      " |      \n",
      " |      Only topological loading (`by_name=False`) is supported when loading weights\n",
      " |      from the TensorFlow format. Note that topological loading differs slightly\n",
      " |      between TensorFlow and HDF5 formats for user-defined classes inheriting from\n",
      " |      `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the\n",
      " |      TensorFlow format loads based on the object-local names of attributes to\n",
      " |      which layers are assigned in the `Model`'s constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath: String, path to the weights file to load. For weight files in\n",
      " |              TensorFlow format, this is the file prefix (the same as was passed\n",
      " |              to `save_weights`). This can also be a path to a SavedModel\n",
      " |              saved from `model.save`.\n",
      " |          by_name: Boolean, whether to load weights by name or by topological\n",
      " |              order. Only topological loading is supported for weight files in\n",
      " |              TensorFlow format.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers where there is\n",
      " |              a mismatch in the number of weights, or a mismatch in the shape of\n",
      " |              the weight (only valid when `by_name=True`).\n",
      " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
      " |              options for loading weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          When loading a weight file in TensorFlow format, returns the same status\n",
      " |          object as `tf.train.Checkpoint.restore`. When graph building, restore\n",
      " |          ops are run automatically as soon as the network is built (on first call\n",
      " |          for user-defined classes inheriting from `Model`, immediately if it is\n",
      " |          already built).\n",
      " |      \n",
      " |          When loading weights in HDF5 format, returns `None`.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available and the weight file is in HDF5\n",
      " |              format.\n",
      " |          ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
      " |            `False`.\n",
      " |  \n",
      " |  make_predict_function(self)\n",
      " |      Creates a function that executes one step of inference.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.predict` and `Model.predict_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.predict_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.predict` or\n",
      " |      `Model.predict_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return the outputs of the `Model`.\n",
      " |  \n",
      " |  make_test_function(self)\n",
      " |      Creates a function that executes one step of evaluation.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.evaluate` and `Model.test_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.test_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.evaluate` or\n",
      " |      `Model.test_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_test_batch_end`.\n",
      " |  \n",
      " |  make_train_function(self)\n",
      " |      Creates a function that executes one step of training.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
      " |      logic to `Model.train_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.fit` or\n",
      " |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches. This method is designed for performance in\n",
      " |      large scale inputs. For small amount of inputs that fit in one batch,\n",
      " |      directly using `__call__` is recommended for faster execution, e.g.,\n",
      " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
      " |      `tf.keras.layers.BatchNormalization` that behaves differently during\n",
      " |      inference. Also, note the fact that test loss is not affected by\n",
      " |      regularization layers like noise and dropout.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input samples. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A `tf.data` dataset.\n",
      " |            - A generator or `keras.utils.Sequence` instance.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per batch.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
      " |              dataset and `steps` is None, `predict` will\n",
      " |              run until the input dataset is exhausted.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during prediction.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`. Note that Model.predict uses the same interpretation rules as\n",
      " |      `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all\n",
      " |      three methods.\n",
      " |      \n",
      " |      `Model.predict` is not yet supported with\n",
      " |      `tf.distribute.experimental.ParameterServerStrategy`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.predict` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.predict` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays (in case the\n",
      " |                model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors (in case the model has\n",
      " |                multiple inputs).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.predict_on_batch` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of mismatch between given number of inputs and\n",
      " |            expectations of the model.\n",
      " |  \n",
      " |  predict_step(self, data)\n",
      " |      The logic for one inference step.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.make_predict_function`.\n",
      " |      \n",
      " |      This method should contain the mathematical logic for one step of inference.\n",
      " |      This typically includes the forward pass.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_predict_function`, which can also be overridden.\n",
      " |      \n",
      " |      Args:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The result of one inference step, typically the output of calling the\n",
      " |        `Model` on data.\n",
      " |  \n",
      " |  reset_metrics(self)\n",
      " |      Resets the state of all the metrics in the model.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> _ = model.fit(x, y, verbose=0)\n",
      " |      >>> assert all(float(m.result()) for m in model.metrics)\n",
      " |      \n",
      " |      >>> model.reset_metrics()\n",
      " |      >>> assert all(float(m.result()) == 0 for m in model.metrics)\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None, save_traces=True)\n",
      " |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
      " |      \n",
      " |      Please see `tf.keras.models.save_model` or the\n",
      " |      [Serialization and Saving guide](https://keras.io/guides/serialization_and_saving/)\n",
      " |      for details.\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath: String, PathLike, path to SavedModel or H5 file to save the\n",
      " |              model.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |          save_format: Either `'tf'` or `'h5'`, indicating whether to save the\n",
      " |              model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,\n",
      " |              and 'h5' in TF 1.X.\n",
      " |          signatures: Signatures to save with the SavedModel. Applicable to the\n",
      " |              'tf' format only. Please see the `signatures` argument in\n",
      " |              `tf.saved_model.save` for details.\n",
      " |          options: (only applies to SavedModel format)\n",
      " |              `tf.saved_model.SaveOptions` object that specifies options for\n",
      " |              saving to SavedModel.\n",
      " |          save_traces: (only applies to SavedModel format) When enabled, the\n",
      " |              SavedModel will store the function traces for each layer. This\n",
      " |              can be disabled, so that only the configs of each layer are stored.\n",
      " |              Defaults to `True`. Disabling this will decrease serialization time\n",
      " |              and reduce file size, but it requires that all custom layers/models\n",
      " |              implement a `get_config()` method.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True, save_format=None, options=None)\n",
      " |      Saves all layer weights.\n",
      " |      \n",
      " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
      " |      argument.\n",
      " |      \n",
      " |      When saving in HDF5 format, the weight file has:\n",
      " |        - `layer_names` (attribute), a list of strings\n",
      " |            (ordered names of model layers).\n",
      " |        - For every layer, a `group` named `layer.name`\n",
      " |            - For every such layer group, a group attribute `weight_names`,\n",
      " |                a list of strings\n",
      " |                (ordered names of weights tensor of the layer).\n",
      " |            - For every weight in the layer, a dataset\n",
      " |                storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      When saving in TensorFlow format, all objects referenced by the network are\n",
      " |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
      " |      instances or `Optimizer` instances assigned to object attributes. For\n",
      " |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
      " |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
      " |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
      " |      `Layer` instances must be assigned to object attributes, typically in the\n",
      " |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
      " |      `tf.keras.Model` for details.\n",
      " |      \n",
      " |      While the formats are the same, do not mix `save_weights` and\n",
      " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
      " |      loaded using `Model.load_weights`. Checkpoints saved using\n",
      " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
      " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
      " |      `save_weights` for training checkpoints.\n",
      " |      \n",
      " |      The TensorFlow format matches objects and variables by starting at a root\n",
      " |      object, `self` for `save_weights`, and greedily matching attribute\n",
      " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
      " |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
      " |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
      " |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
      " |      the `Model`'s variables. See the [guide to training\n",
      " |      checkpoints](https://www.tensorflow.org/guide/checkpoint) for details\n",
      " |      on the TensorFlow format.\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath: String or PathLike, path to the file to save the weights to.\n",
      " |              When saving in TensorFlow format, this is the prefix used for\n",
      " |              checkpoint files (multiple files are generated). Note that the '.h5'\n",
      " |              suffix causes weights to be saved in HDF5 format.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
      " |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
      " |              `None` defaults to 'tf'.\n",
      " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
      " |              options for saving weights.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available when attempting to save in HDF5\n",
      " |              format.\n",
      " |          ValueError: For invalid/unknown format arguments.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Args:\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use. Defaults to `print`.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays (in case the\n",
      " |                model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors (in case the model has\n",
      " |                multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors, if\n",
      " |                the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.test_on_batch` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  test_step(self, data)\n",
      " |      The logic for one evaluation step.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.make_test_function`.\n",
      " |      \n",
      " |      This function should contain the mathematical logic for one step of\n",
      " |      evaluation.\n",
      " |      This typically includes the forward pass, loss calculation, and metrics\n",
      " |      updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_test_function`, which can also be overridden.\n",
      " |      \n",
      " |      Args:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A YAML string.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: if yaml module is not found.\n",
      " |  \n",
      " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |                if the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
      " |            weight (float) to apply to the model's loss for the samples from this\n",
      " |            class during training. This can be useful to tell the model to \"pay\n",
      " |            more attention\" to samples from an under-represented class.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If `model.train_on_batch` is wrapped in `tf.function`.\n",
      " |        ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  train_step(self, data)\n",
      " |      The logic for one training step.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      This method is called by `Model.make_train_function`.\n",
      " |      \n",
      " |      This method should contain the mathematical logic for one step of training.\n",
      " |      This typically includes the forward pass, loss calculation, backpropagation,\n",
      " |      and metric updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_train_function`, which can also be overridden.\n",
      " |      \n",
      " |      Args:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned. Example:\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  distribute_strategy\n",
      " |      The `tf.distribute.Strategy` this model was created under.\n",
      " |  \n",
      " |  layers\n",
      " |  \n",
      " |  metrics\n",
      " |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
      " |      \n",
      " |      Note: Metrics passed to `compile()` are available only after a `keras.Model`\n",
      " |      has been trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> model.fit(x, y)\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.add_metric(\n",
      " |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> model.fit(x, (y, y))\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc', 'mean']\n",
      " |  \n",
      " |  metrics_names\n",
      " |      Returns the model's display labels for all outputs.\n",
      " |      \n",
      " |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
      " |      trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> model.metrics_names\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> model.fit(x, y)\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> model.fit(x, (y, y))\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc']\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are expected\n",
      " |      to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  state_updates\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  run_eagerly\n",
      " |      Settable attribute indicating whether the model should run eagerly.\n",
      " |      \n",
      " |      Running eagerly means that your model will be run step by step,\n",
      " |      like Python code. Your model might run slower, but it should become easier\n",
      " |      for you to debug it by stepping into individual layer calls.\n",
      " |      \n",
      " |      By default, we will attempt to compile your model to a static graph to\n",
      " |      deliver the best execution performance.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Boolean, whether the model should run eagerly.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Args:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |        - If the layer is not built, the method will call `build`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |            inputs - Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(inputs))\n",
      " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This is\n",
      " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result of\n",
      " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
      " |          using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Args:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first input node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first output node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function, by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
      " |      and the bias vector. These can be used to set the weights of another\n",
      " |      `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a list of NumPy arrays. The number\n",
      " |          of arrays and their shape must match\n",
      " |          number of the dimensions of the weights\n",
      " |          of the layer (i.e. it should match the\n",
      " |          output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided weights list does not match the\n",
      " |          layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
      " |      computations and the output to be in the compute dtype as well. This is done\n",
      " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
      " |      these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision when\n",
      " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
      " |      will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
      " |      the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
      " |      of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
      " |      error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be3a450ae056f83d7ade2b901f772a26fc828bc81af96bc522c29bb44d5db4b0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('tf_gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
